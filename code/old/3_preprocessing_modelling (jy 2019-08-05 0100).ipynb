{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# maths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import scipy.stats as stats\n",
    "#from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# visual\n",
    "#from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression, Ridge, Lasso, ElasticNet, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.metrics import r2_score,mean_squared_error,confusion_matrix,accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, BaggingClassifier, RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "\n",
    "# nlp\n",
    "#from sklearn.feature_extraction.text import CountVectorizer,HashingVectorizer,TfidfVectorizer\n",
    "#from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "#from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "#from sklearn.svm import SVC\n",
    "#from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "#from nltk.corpus import stopwords\n",
    "#from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "#import spacy\n",
    "#from spacy.tokens import Doc\n",
    "\n",
    "# web\n",
    "#import requests\n",
    "#import json\n",
    "\n",
    "# others\n",
    "#import os\n",
    "#import re\n",
    "#import time\n",
    "#import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "input_path = '../data/2_input/'\n",
    "clean_path = '../data/3_clean/'\n",
    "output_path = '../data/4_output/'\n",
    "\n",
    "image_path = '../images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clean data\n",
    "\n",
    "df_train = pd.read_csv(clean_path + 'train_clean.csv')\n",
    "df_test = pd.read_csv(clean_path + 'test_clean.csv')\n",
    "df_weather = pd.read_csv(clean_path + 'weather_clean.csv')\n",
    "#df_spray = pd.read_csv(clean_path + 'spray_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train.columns)\n",
    "print(df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines test and train datasets for processing\n",
    "test = df_test.drop('id', axis=1) #id not in train dataset\n",
    "train = df_train.drop(['nummosquitos', 'wnvpresent'], axis=1) #nummosquitos and wnvpresent not in test dataset\n",
    "combined_train_test = pd.concat([train,test], sort=False)\n",
    "combined_train_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "combined_train_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using weather data only from Station 1\n",
    "only_station_1 = df_weather[df_weather['station'] == 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines weather data with train and test dataset\n",
    "all_dataset = combined_train_test.merge(only_station_1, how='left', on=['year','month','day'])\n",
    "all_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dummies for categorical data\n",
    "df_get_dum = pd.concat([all_dataset, pd.get_dummies(all_dataset[['species', 'street', 'trap']],drop_first=True)], axis=1)\n",
    "df_get_dum.drop(['species', 'street', 'trap'], inplace =True, axis=1)\n",
    "df_get_dum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_get_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits out train dataset and re-attach wnvpresent column\n",
    "train = df_get_dum[df_get_dum['year']%2!=0]\n",
    "wnv = pd.DataFrame(df_train['wnvpresent'])\n",
    "train_with_wnv = train.merge(wnv, left_on=train.index, right_on=wnv.index)\n",
    "train_with_wnv['nummosquitos'] = df_train['nummosquitos']\n",
    "train_with_wnv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_with_wnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits out test dataset\n",
    "test = df_get_dum.loc[df_get_dum['year']%2==0]\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits train dataset into majority and minority classes based on wnvpresent column 1, 0\n",
    "majority_class = train_with_wnv[train_with_wnv['wnvpresent']==0]\n",
    "minority_class = train_with_wnv[train_with_wnv['wnvpresent']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resamples minority class i.e. wnvpresent = 1, with duplicates to increase representation\n",
    "minority_upsampled = resample( minority_class, replace=True, n_samples=majority_class.shape[0], random_state=42)\n",
    "train_resampled = pd.concat([minority_upsampled,majority_class])\n",
    "train_resampled.wnvpresent.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffles dataset\n",
    "df = shuffle(train_resampled, random_state=42)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "for x in list(df.columns):\n",
    "    if 'street' in x:\n",
    "        pass\n",
    "    elif 'trap' in x:\n",
    "        pass\n",
    "    else:\n",
    "        count += 1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df.iloc[:,:31]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.drop(columns=['key_0', 'block', 'station'], inplace=True)\n",
    "y_mos_count = df.nummosquitos\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_mos_count, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = list(X.columns)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'linreg': LinearRegression(),\n",
    "    'ridge': Ridge(),\n",
    "    'lasso': Lasso(),\n",
    "    'en': ElasticNet(),\n",
    "    'rfr': RandomForestRegressor()\n",
    "}.items()\n",
    "\n",
    "params = {\n",
    "    'linreg': {\n",
    "        'linreg__n_jobs': [1]\n",
    "    },\n",
    "    'ridge': {\n",
    "        'ridge__alpha': np.logspace(-2, 3, 200)\n",
    "    },\n",
    "    'lasso': {\n",
    "        'lasso__alpha': np.logspace(-2, 3, 200)\n",
    "    },\n",
    "    'en': {\n",
    "        'en__l1_ratio': np.linspace(0.01, 1.0, 5),\n",
    "        'en__alpha': np.logspace(-2, 3, 200)\n",
    "    },\n",
    "    'rfr': {\n",
    "        'rfr__n_estimators': [10, 20, 30]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "models = []\n",
    "parameters = []\n",
    "test_score = []\n",
    "\n",
    "for k,v in estimators:\n",
    "    pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        (k,v)])\n",
    "    \n",
    "    param = params[k]\n",
    "    \n",
    "    gridsearch = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param,\n",
    "        verbose=1,\n",
    "        n_jobs=3,\n",
    "    )\n",
    "\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    \n",
    "    model = gridsearch.best_estimator_\n",
    "    score = model.score(X_test, y_test)\n",
    "    best_params = gridsearch.best_params_\n",
    "\n",
    "    # predict y\n",
    "    #y_pred = model.predict(X_test)\n",
    "    \n",
    "    # print results\n",
    "    print(\"Model: \", k)\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best R2 score:\", gridsearch.best_score_)\n",
    "    print(\"Test R2 score:\", score)\n",
    "    \n",
    "    # append info to list\n",
    "    models.append(k)\n",
    "    test_score.append(score)\n",
    "    parameters.append(best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary of results\n",
    "pd.DataFrame({\n",
    "    'model': models,\n",
    "    'parameters': parameters,\n",
    "    'test_score': test_score\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kaggle.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Random Forest Regressor has the highest score in predicting the number of mosquitos. \n",
    "\n",
    "model = RandomForestRegressor(n_estimators=20).fit(X_train, y_train)\n",
    "\n",
    "features = list(X.columns)\n",
    "X_kaggle = test[features]\n",
    "\n",
    "test['nummosquitos'] = model.predict(X_kaggle)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['nummosquitos'] = test['nummosquitos'].map(lambda x:int(x))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df.wnvpresent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'Lr': LogisticRegression(),\n",
    "    'Knn': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Dtree': DecisionTreeClassifier(),\n",
    "    'Rf': RandomForestClassifier()\n",
    "}.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in estimators:\n",
    "    pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        (k,v)])\n",
    "    model = pipe.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print('{} score: {} AUC/ROC: {}'.format(k, model.score(X_train,y_train), roc_auc_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
