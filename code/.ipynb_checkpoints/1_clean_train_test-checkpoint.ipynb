{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# maths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import scipy.stats as stats\n",
    "#from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# visual\n",
    "#from matplotlib_venn import venn2\n",
    "#import seaborn as sns\n",
    "#import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "# from sklearn import linear_model\n",
    "# from sklearn.linear_model import Ridge,LinearRegression,LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "# from sklearn.metrics import r2_score,mean_squared_error,confusion_matrix,accuracy_score\n",
    "# from sklearn.pipeline import make_pipeline,Pipeline\n",
    "\n",
    "# nlp\n",
    "# from sklearn.feature_extraction.text import CountVectorizer,HashingVectorizer,TfidfVectorizer\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "# from nltk.stem import PorterStemmer,WordNetLemmatizer\n",
    "# from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "# import spacy\n",
    "# from spacy.tokens import Doc\n",
    "\n",
    "# web\n",
    "#import requests\n",
    "#import json\n",
    "\n",
    "# others\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "input_path = '../data/2_input/'\n",
    "clean_path = '../data/3_clean/'\n",
    "output_path = '../data/4_output/'\n",
    "\n",
    "image_path = '../images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(input_path+'train.csv')\n",
    "test = pd.read_csv(input_path+'test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yr(x): \n",
    "    return x.split('-')[0] \n",
    "\n",
    "def create_mth(x): \n",
    "    return x.split('-')[1] \n",
    "\n",
    "def create_day(x): \n",
    "    return x.split('-')[2] \n",
    "\n",
    "def rename_columns (columns):\n",
    "    return [column.lower() for column in columns]\n",
    "\n",
    "def clean_data(df): \n",
    "    df['year'] = df.Date.apply(create_yr)\n",
    "    df['month'] = df.Date.apply(create_mth)\n",
    "    df['day'] = df.Date.apply(create_day)\n",
    "    \n",
    "    #df['latitude'] = df.Latitude.apply(int)\n",
    "    #df['longitude'] = df.Longitude.apply(int)\n",
    "    df['latitude'] = df.Latitude\n",
    "    df['longitude'] = df.Longitude\n",
    "    \n",
    "    df.drop(['Address', 'AddressNumberAndStreet', 'AddressAccuracy', 'Date', 'Latitude', 'Longitude'], axis = 1, inplace = True)\n",
    "    df.columns = rename_columns(df.columns)\n",
    "    return df\n",
    "\n",
    "train = clean_data(train)\n",
    "test = clean_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train[train.nummosquitos==50].shape\n",
    "\n",
    "#train[train.nummosquitos==50]\n",
    "\n",
    "#train[train.duplicated()]\n",
    "\n",
    "#col = [col for col in train.columns if col not in ['nummosquitos','wnvpresent']]\n",
    "\n",
    "#col\n",
    "\n",
    "#train.groupby(train.columns.tolist(),as_index=False).size()\n",
    "\n",
    "#train.duplicated(col).sum()\n",
    "\n",
    "#train[train.duplicated(col)]\n",
    "\n",
    "#test.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cols = ['species','trap','year','month', 'day','latitude','longitude']\n",
    "# cols = ['species','trap','year','month', 'day']\n",
    "\n",
    "# mask_dulipcated = train.duplicated(subset=cols, keep=False)\n",
    "\n",
    "# print(train[mask_dulipcated].shape)\n",
    "# train[mask_dulipcated]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge nummosquitos and wnvpresent for duplicated rows\n",
    "\n",
    "train_2 = train.copy()\n",
    "\n",
    "cols = ['species','trap','year','month', 'day','latitude','longitude']\n",
    "\n",
    "for row_idx,row in train_2.iterrows():\n",
    "    \n",
    "    if row_idx > 0:\n",
    "        \n",
    "        duplicate_count = 0        \n",
    "        \n",
    "        for col in cols:\n",
    "            \n",
    "            if train_2.at[row_idx,col] == train_2.at[row_idx-1,col]:\n",
    "                duplicate_count += 1               \n",
    "                \n",
    "        if duplicate_count == len(cols):\n",
    "            train_2.at[row_idx,'nummosquitos'] = train_2.at[row_idx-1,'nummosquitos'] + train_2.at[row_idx,'nummosquitos']\n",
    "            train_2.at[row_idx,'wnvpresent'] = train_2.at[row_idx-1,'wnvpresent'] + train_2.at[row_idx,'wnvpresent']\n",
    "\n",
    "# remove duplicated rows (keep only last row)\n",
    "train_2.drop_duplicates(subset=cols, keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check total nummosquitos and wnvpresent\n",
    "\n",
    "print(train['nummosquitos'].sum())\n",
    "print(train['wnvpresent'].sum())\n",
    "print('')\n",
    "print(train_2['nummosquitos'].sum())\n",
    "print(train_2['wnvpresent'].sum())\n",
    "print('')\n",
    "print(train_2['wnvpresent'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert wnvpresent: total count to 0 or 1\n",
    "\n",
    "for row_idx,row in train_2.iterrows():\n",
    "    \n",
    "    if row['wnvpresent'] > 1:\n",
    "        #print(row_idx,row['wnvpresent'])\n",
    "        train_2.at[row_idx,'wnvpresent'] = 1\n",
    "        \n",
    "print(train_2['wnvpresent'].sum())\n",
    "print(train_2['wnvpresent'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_2.to_csv(clean_path+'train_clean.csv',index=False)\n",
    "test.to_csv(clean_path+'test_clean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
