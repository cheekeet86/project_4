{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.  Preprocessing & Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to use the datasets provided to build a model that predicts the presence of the West Nile Virus. The model is meant for use by the City of Chicago for decisions involving pesticide spray.\n",
    "\n",
    "### Contents:\n",
    "- [Import Libraries](#Import-Libraries)\n",
    "- [Import Data](#Import-Data)\n",
    "- [Data prepared for Modelling](#Data-prepared-for-Modelling)\n",
    "- [Modelling](#Modelling)\n",
    "- [Models Evaluation & Next Steps](#Models-Evaluation-&-Next-Steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the necessary libraries used in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# maths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# visual\n",
    "#from matplotlib_venn import venn2\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# modelling\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler,PolynomialFeatures\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix,accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample, shuffle\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier, RandomForestRegressor, GradientBoostingClassifier\n",
    "\n",
    "# Others\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import the datasets with standardised file paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "input_path = '../data/2_input/'\n",
    "clean_path = '../data/3_clean/'\n",
    "output_path = '../data/4_output/'\n",
    "\n",
    "image_path = '../images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datasets imported here have already been cleaned for null values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import clean data\n",
    "\n",
    "df_train = pd.read_csv(clean_path + 'train_clean.csv')\n",
    "df_test = pd.read_csv(clean_path + 'test_clean.csv')\n",
    "df_weather = pd.read_csv(clean_path + 'weather_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Size of train dataset: {}'.format(df_train.shape))\n",
    "print('Size of test dataset: {}'.format(df_test.shape))\n",
    "print('Size of weather dataset: {}'.format(df_weather.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data prepared for Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We combine train and test data to prepare the datasets for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drops id column from test not in train\n",
    "test = df_test.drop('id', axis=1)\n",
    "#Drops nummosquitos and wnvpresent columns from train not in test\n",
    "train = df_train.drop(['nummosquitos', 'wnvpresent'], axis=1)\n",
    "\n",
    "#Combines train and test datasets\n",
    "combined_train_test = pd.concat([test,train])\n",
    "\n",
    "print('Size of train/test dataset: {}'.format(combined_train_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The weather dataset gives us information of weather conditions from 2007 to 2014, during the months of the virus tests. It includes data from two weather stations:\n",
    "\n",
    "<br>Station 1: CHICAGO O'HARE INTERNATIONAL AIRPORT Lat: 41.995 Lon: -87.933 Elev: 662 ft. above sea level\n",
    "<br>Station 2: CHICAGO MIDWAY INTL ARPT Lat: 41.786 Lon: -87.752 Elev: 612 ft. above sea level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data from each station and combine it across columns to prevent duplication of data points on columns in the main dataset. Then merge it with the train/test dataset to add information on weather conditions on the dates of virus test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits weather data by Station\n",
    "only_station_1 = df_weather[df_weather['station'] == 1].reset_index(drop=True)\n",
    "only_station_2 = df_weather[df_weather['station'] == 2].reset_index(drop=True)\n",
    "\n",
    "#Renames Station 2 data for differentiation\n",
    "only_station_2.columns = [str(col) + '_2' for col in only_station_2.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine weather data from both stations across columns and drop Station columns\n",
    "parallel_weather = pd.concat([only_station_1,only_station_2], axis=1).drop(['station','station_2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print combined weather data\n",
    "parallel_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combines weather data with train and test dataset\n",
    "all_dataset = combined_train_test.merge(parallel_weather, how='left', on=['year','month','day'])\n",
    "\n",
    "print('Size of train/test dataset with weather data: {}'.format(all_dataset.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prints train/test dataset with weather information\n",
    "all_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the categorical data, we use One Hot Encoding to convert them to numerical data and drop the first column of each categorical feature as it represents duplicated information. We also drop the original columns with non-numeric values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converts categorical data into numeric\n",
    "df_get_dum = pd.concat([all_dataset, pd.get_dummies(all_dataset[['species', 'street', 'trap']],drop_first=True)], axis=1)\n",
    "df_get_dum.drop(['species', 'street', 'trap'], inplace =True, axis=1)\n",
    "\n",
    "print('Size of train/test dataset with weather data(One Hot Encoded): {}'.format(df_get_dum.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data back into seperate train and test datasets and only use train for training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits out train dataset using year\n",
    "train = df_get_dum[df_get_dum['year']%2!=0]\n",
    "train.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Re-attaching original wnvpresent column\n",
    "wnv = pd.Series(df_train['wnvpresent'])\n",
    "train_with_wnv = pd.concat([train , wnv], axis=1)\n",
    "\n",
    "print('Size of processed train data: {}'.format(train_with_wnv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits out test dataset using year\n",
    "test = df_get_dum.loc[df_get_dum['year']%2==0]\n",
    "print('Size of processed train data: {}'.format(test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also note that the data is imbalanced. Out of the 8475 rows in our training dataset, only 457 (~5%) data points represent the virus present class while 8018 represent virus not present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Size of training data\n",
    "train_with_wnv.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Representation of classes\n",
    "train_with_wnv.wnvpresent.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To handle the imbalanced data, we conduct oversampling on the minority class i.e. the data points where wnv is present. While undersampling is an option, we decide that undersampling the majority class to match the size of the minority class dataset will reduce the data points immensely, and is hence not ideal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first split the data into the classes. Then, resample minority class with replacement until there are 8018 data points before combining the new minority dataset with the original majority class dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splits data by presence of wnv\n",
    "majority_class = train_with_wnv[train_with_wnv['wnvpresent']==0]\n",
    "minority_class = train_with_wnv[train_with_wnv['wnvpresent']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resamples minority class with replacement\n",
    "minority_upsampled = resample( minority_class, replace=True, n_samples=majority_class.shape[0], random_state=42)\n",
    "\n",
    "#Combine new minority class dataset with original majority class dataset\n",
    "train_resampled = pd.concat([minority_upsampled,majority_class])\n",
    "\n",
    "#Checks class representation\n",
    "train_resampled.wnvpresent.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shuffle the dataset to inject randomness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shuffles dataset\n",
    "df = shuffle(train_resampled, random_state=42)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print resampled, reshuffled new dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use all the features in the dataset to fit classification models and identify wnvpresent to be our target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['wnvpresent'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.wnvpresent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline prediction is all 0 as the dataset is imbalanced, hence the simplest way is to predict the majority class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_pred = np.zeros(y.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(y,baseline_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ROC/AUC score of 0.5 means the model has no class separation capacity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is split into random train and test subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the model on the following classifiers and test its performance using ROC/AUC score:\n",
    "    <br> - Logistic Regression, \n",
    "    <br> - KNearestNeighbour Classifier, \n",
    "    <br> - Decision Tree Classifier,\n",
    "    <br> - Random Forest Classifier,\n",
    "    <br> - Adaboost Classifier,\n",
    "    <br> - Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {\n",
    "    'Lr': LogisticRegression(),\n",
    "    'Knn': KNeighborsClassifier(n_neighbors=5),\n",
    "    'Dtree': DecisionTreeClassifier(),\n",
    "    'Rf': RandomForestClassifier(),\n",
    "    'Adaboost': AdaBoostClassifier(),\n",
    "    'GradientBoost': GradientBoostingClassifier()\n",
    "}.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a pipeline to scale the data before fitting to the classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for k,v in estimators:\n",
    "    pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        (k,v)])\n",
    "    model = pipe.fit(X_train,y_train)\n",
    "    pred = model.predict(X_test)\n",
    "    print('{} Model Score: {}, Cross-Validation Standard Deviation: {}'.format(k, round(model.score(X_train,y_train),5), round(cross_val_score(model,X,y,cv=3, scoring='roc_auc').std(),5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models were scored on training data(X_train) to determine the model's performance. Cross validation was performed on the whole train data set using metrics of ROC/AUC to determine if the model is able to generalise to data that it was not trained on.\n",
    "<p>From the model score and standard deviation of the cross validation scores of the classifiers, we see that the best classifiers are decision tree and random forest. Decision tree had a score of 1.0 as it is a greedy model that will find the best split.\n",
    "<p>As such, we will tune the hyperparameters of decision tree and random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Tuning hyperparameters through GridSearch<b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "\n",
    "    'Dtree': {\n",
    "        'Dtree__max_features': ['auto', 'log2', None, 50, 100, 200],\n",
    "        'Dtree__max_depth': [None, 5, 10, 15],\n",
    "        'Dtree__min_samples_split': np.linspace(0.1, 0.5, 5)\n",
    "    },\n",
    "    'Rf': {\n",
    "        'Rf__n_estimators': [10, 20, 50, 100],\n",
    "        'Rf__max_depth': [None, 5, 10, 15],\n",
    "        'Rf__max_features': ['auto', 'log2', None, 50, 100, 200],\n",
    "        'Rf__min_samples_split': np.linspace(0.1, 0.5, 5)\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "parameters = []\n",
    "best_score = []\n",
    "roc_auc = []\n",
    "\n",
    "shortlist_estimators = {\n",
    "    'Dtree': DecisionTreeClassifier(),\n",
    "    'Rf': RandomForestClassifier(),\n",
    "}.items()\n",
    "\n",
    "for k,v in shortlist_estimators:\n",
    "    pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        (k,v)])\n",
    "    \n",
    "    param = params[k]\n",
    "    \n",
    "    gridsearch = GridSearchCV(\n",
    "        estimator=pipe,\n",
    "        param_grid=param,\n",
    "        verbose=1,\n",
    "        cv= 3,\n",
    "        n_jobs=-1,\n",
    "        return_train_score= True,\n",
    "        scoring = 'roc_auc'\n",
    "    )\n",
    "\n",
    "    gridsearch.fit(X_train, y_train)\n",
    "    \n",
    "    model = gridsearch.best_estimator_\n",
    "    cv_score = gridsearch.cv_results_\n",
    "    best_params = gridsearch.best_params_\n",
    "\n",
    "    # predict y\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # print results\n",
    "    print(\"Model: \", k)\n",
    "    print(\"Best parameters:\", best_params)\n",
    "    print(\"Best score:\", gridsearch.best_score_)\n",
    "    print(\"AUC/ROC test:\", roc_auc_score(y_test,y_pred))\n",
    "    display(pd.DataFrame(cv_score, columns = cv_score.keys()))\n",
    "    \n",
    "    \n",
    "    # append info to list\n",
    "    models.append(k)\n",
    "    best_score.append(gridsearch.best_score_)\n",
    "    parameters.append(best_params)\n",
    "    roc_auc.append(roc_auc_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print summary of results\n",
    "summary = pd.DataFrame({\n",
    "    'model': models,\n",
    "    'parameters': parameters,\n",
    "    'best score': best_score,\n",
    "    'roc/auc test': roc_auc\n",
    "})\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction on kaggle test set\n",
    "\n",
    "The best parameters from gridsearch were used for prediction on the kaggle test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for decision tree\n",
    "pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        ('Dtree', DecisionTreeClassifier(min_samples_split=0.1))])\n",
    "    \n",
    "model = pipe.fit(X_train,y_train)\n",
    "pred = model.predict_proba(test)\n",
    "pred = pd.DataFrame(pred, columns=[0,1])\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['WnvPresent'] = pred[1]\n",
    "submission['Id'] = submission.index + 1\n",
    "submission[['Id', 'WnvPresent']].to_csv(output_path+'submission_dtree.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction for random forest\n",
    "pipe = Pipeline([\n",
    "        ('sc', StandardScaler()),\n",
    "        ('rf', RandomForestClassifier(max_features='log2', min_samples_split=0.1, n_estimators=50))])\n",
    "\n",
    "model = pipe.fit(X_train,y_train)\n",
    "pred = model.predict_proba(test)\n",
    "pred = pd.DataFrame(pred, columns=[0,1])\n",
    "\n",
    "submission = pd.DataFrame()\n",
    "submission['WnvPresent'] = pred[1]\n",
    "submission['Id'] = submission.index + 1\n",
    "submission[['Id', 'WnvPresent']].to_csv(output_path+'submission_rf.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Evaluation & Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used both Decision Tree and Random Forest models to predict on the kaggle test set and the results obtained were as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename= image_path + 'submission_dtree_rf.PNG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences between the kaggle scores and the training scores indicated that our models were overfitted. <p>Therefore, we proceeded to explore more work to better prepare the data for modelling (refer to other notebooks):\n",
    "1. Regression to predict number of mosquitos - The number of mosquitos was not provided in the kaggle test set and was not considered in the previous model. We will predict the number of mosquitos first before predicting the probability of virus. \n",
    "2. Oversampling via SMOTE\n",
    "\n",
    "Random Forest Classification was used in the exploration as Decision Tree is prone to overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
