{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Header\n",
    "\n",
    "In this notebook, we will clean the weather dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "# maths\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime as datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file paths\n",
    "\n",
    "input_path = '../data/2_input/'\n",
    "clean_path = '../data/3_clean/'\n",
    "output_path = '../data/4_output/'\n",
    "\n",
    "image_path = '../images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions\n",
    "\n",
    "Similar to the train and test dataset, we had split the data feature into `year`, `month` and `day` columns. Based on the first few rows of the data, it appears that there are some missing values in the dataset, labelled as `M`, `-` and `T`. Hence, we also created functions to summarise these 'null' values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dates\n",
    "\n",
    "def create_yr(x): \n",
    "    return x.split('-')[0] \n",
    "\n",
    "def create_mth(x): \n",
    "    return x.split('-')[1] \n",
    "\n",
    "def create_day(x): \n",
    "    return x.split('-')[2] \n",
    "\n",
    "def rename_columns (columns):\n",
    "    return [column.lower() for column in columns]\n",
    "\n",
    "def clean_date(df): \n",
    "    df.columns = rename_columns(df.columns)\n",
    "    df['year'] = df.date.apply(create_yr)\n",
    "    df['month'] = df.date.apply(create_mth)\n",
    "    df['day'] = df.date.apply(create_day)\n",
    "    df.drop('date', axis=1, inplace = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_t(x): \n",
    "    if x == '  T':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def count_m(x): \n",
    "    if x == 'M':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def count_dash(x): \n",
    "    if x == '-':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "# count total number of M - T in df\n",
    "\n",
    "def print_summary(df):    \n",
    "\n",
    "    cols = ['column','M','-','T']\n",
    "    df_summary = pd.DataFrame(columns=cols)\n",
    "    idx = 0\n",
    "\n",
    "    for col in df.columns:\n",
    "\n",
    "        if df[col].dtype == 'object':\n",
    "\n",
    "            total_m = df[col].apply(count_m).sum()\n",
    "            total_dash = df[col].apply(count_dash).sum()\n",
    "            total_t = df[col].apply(count_t).sum()\n",
    "\n",
    "            df_summary.at[idx,cols[0]] = col\n",
    "            df_summary.at[idx,cols[1]] = total_m\n",
    "            df_summary.at[idx,cols[2]] = total_dash\n",
    "            df_summary.at[idx,cols[3]] = total_t\n",
    "\n",
    "        idx += 1\n",
    "    \n",
    "    return df_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import weather data\n",
    "\n",
    "df = pd.read_csv(input_path + 'weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect Data\n",
    "\n",
    "As indicated below, the weather dataset has 2944 rows and 22 features. Some of the columns' datatypes are listed as object as they contain missing values. We will need to rectify those later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print first 5 records\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all columns\n",
    "\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df summary\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_date(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check columns type\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As indicated in the summary below, half of the entries (1472 out of 2944) in `depart`, `sunrise` and `sunset` columns have missing values. For `sunrise` and `sunset` columns, we did some desktop research and understand that this was because station 2 does not collect data for these columns. We have thus decided to impute these missing values with values from station 1. \n",
    "\n",
    "For column `water1`, all of its entries are missing values `M`, hence we should drop this column. We have also decided to drop `snowfall` and `depth` columns as their entries are either 0 or missing. \n",
    "\n",
    "There are `T` values in `snowfall` and `precitotal`. Based on the data documentation, this means that there are trace precipitate for that entry. Hence, we decided to round these values to 0. For the missing values in `preciptotal`, we decided to impute it with median values. Likewise for `avgspeed`, `sealevel` and `stnpressure`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# count total number of M, -,  T in df\n",
    "\n",
    "print('before cleaning:')\n",
    "df_summary = print_summary(df)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.snowfall.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.depth.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['codesum','water1','snowfall','depth'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while i < df.shape[0]:\n",
    "    df.iloc[i+1, 4] = df.iloc[i, 4] #depart column\n",
    "    df.iloc[i+1, 9] = df.iloc[i, 9] #sunrise\n",
    "    df.iloc[i+1, 10] = df.iloc[i, 10] #sunset\n",
    "    i+=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_tavg(row):\n",
    "    if row['tavg'] == 'M': \n",
    "        row['tavg'] = (row['tmax'] - row['tmin']) * 0.5 + row['tmin']\n",
    "    return row\n",
    "\n",
    "df = df.apply(impute_missing_tavg, axis = 1)\n",
    "df.tavg = df.tavg.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_wetbulb(row): \n",
    "    if row['wetbulb'] == 'M':\n",
    "        row['wetbulb'] = row['tavg']-((row['tavg']-row['dewpoint'])/3)\n",
    "    return row\n",
    "\n",
    "df = df.apply(impute_missing_wetbulb, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_missing_rest(row): \n",
    "\n",
    "    if row['heat'] == 'M':\n",
    "        if row['tavg'] >= 65: \n",
    "            row['heat'] = 0\n",
    "            row['cool'] = row['tavg'] - 65\n",
    "        else: \n",
    "            row['heat'] = 65 - row['tavg']\n",
    "            row['cool'] = 0\n",
    "\n",
    "    if row['preciptotal'] == '  T':\n",
    "        row['preciptotal'] = 0\n",
    "    if row['preciptotal'] == 'M':\n",
    "        row['preciptotal'] = df[df.preciptotal!='M'][df.preciptotal!='  T'].preciptotal.median()       \n",
    "    if row['stnpressure'] == 'M':\n",
    "        row['stnpressure'] = df[df.stnpressure!='M'].stnpressure.median()\n",
    "    if row['sealevel'] == 'M':\n",
    "        row['sealevel'] = df[df.sealevel!='M'].sealevel.median()\n",
    "    if row['avgspeed'] == 'M':\n",
    "        row['avgspeed'] = df[df.avgspeed!='M'].avgspeed.median()    \n",
    "    return row\n",
    "\n",
    "df = df.apply(impute_missing_rest, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "\n",
    "We checked and confirmed that there are no more missing values before saving our processed dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('after cleaning:')    \n",
    "df_summary = print_summary(df)\n",
    "df_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output clean data\n",
    "\n",
    "df.to_csv(clean_path + 'weather_clean.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
